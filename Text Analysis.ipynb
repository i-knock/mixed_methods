{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text analysis\n",
    "## Requisites\n",
    "Done in python as several libraries are good enough for the text analysis, or even better than in R.\n",
    "- Data scraping: `twint`\n",
    "- Data management: `pandas`\n",
    "- Text processing and sentiment analysis: `nltk`\n",
    "  - Look at VADER for the sentiment analysis: `nltk.sentiment.vader.SentimentIntensityAnalyzer`\n",
    "- Plotting: `seaborn` (or the built-in pandas graphs)\n",
    "- Topic analysis: `corextopic`\n",
    "  - <a href='https://github.com/gregversteeg/corex_topic'>Github repo</a>\n",
    "\n",
    "## Steps\n",
    "1. Scrape tweets\n",
    "2. Import the data into pandas\n",
    "3. Process the text (e.g. tokenization, lemmatization, corpus, etc.)\n",
    "4. Word cloud\n",
    "5. Sentiment analysis\n",
    "6. Topic analysis\n",
    "7. Combine both sentiment and topic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scrape tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n",
    "\n",
    "# https://github.com/twintproject/twint/wiki/Configuration\n",
    "\n",
    "hashtags = [\n",
    "    \"#ABPSouthampton\",\n",
    "    \"#DP_World\",\n",
    "    \"#GaPorts\",\n",
    "    \"#PortofHamburg\",\n",
    "    \"#HutchisonPPC\",\n",
    "    \"#LondonPortAuth\",\n",
    "    \"#PANYNJ\",\n",
    "    \"#portdebarcelona\",\n",
    "    \"#PortMTL\",\n",
    "    \"#Port_Houston\",\n",
    "    \"#PortofAntwerp\",\n",
    "    \"#felixstowe_port\",\n",
    "    \"#portoflongbeach\",\n",
    "    \"#PortofLA\",\n",
    "    \"#PortofOakland\",\n",
    "    \"#PortOfRotterdam\",\n",
    "    \"#PortofSeattle\",\n",
    "    \"#PortVancouver\",\n",
    "    \"#Port_Zeebrugge\",\n",
    "    \"#portodigenova\",\n",
    "    \"#PuertoAlgeciras\",\n",
    "    \"#PuertodeCtg\",\n",
    "    \"#SCPorts\",\n",
    "    \"#PortofVirginia\",\n",
    "    \"#AutPortValencia\"\n",
    "]\n",
    "\n",
    "c = twint.Config()\n",
    "c.Output = f\"all_hashtags.csv\"\n",
    "for hashtag in hashtags:\n",
    "    print(\"test\")\n",
    "    c.Limit = 1000\n",
    "    c.Store_csv = True\n",
    "    # c.Search = '\"port\" and \"expansion\"'\n",
    "    # c.Search = '\"port\"'\n",
    "    c.Search = hashtag\n",
    "    c.Filter_retweets = True\n",
    "    c.Lang = \"en\"\n",
    "    twint.run.Search(c)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e1f181429d49be125055ad9515b0eafe15ddb54ea842c1afa9de67712d58328"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('3.9.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
